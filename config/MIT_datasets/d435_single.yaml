%YAML:1.0

#inputs
imu: 1         
imu_topic: "/acl_jackal/forward/imu"
image0_topic: "/acl_jackal/forward/infra1/image_rect_raw"
image1_topic: "/acl_jackal/forward/infra2/image_rect_raw"

is_compressed_images: 1

imu_freq: 400
image_freq: 30
frame_step: 2

#Camera configuration
camera_configuration: 0  #STEREO_PINHOLE = 0, STEREO_FISHEYE = 1, PINHOLE_DEPTH = 2, FOURCORNER_FISHEYE = 3
num_of_cam: 2
cam0_calib: "infra.yaml"
cam1_calib: "infra.yaml"
image_width: 640
image_height: 480

body_T_cam0: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [0.9998495663564139, -0.01332358982788149, 0.01110525150501032, -0.03068970324656957,
         0.01316436364820382, 0.9998112331832488, 0.01428977012863299, -0.06789244691763885,
         -0.01129354623796312, -0.01414142689722982, 0.9998362245181364, 0.03980004121672052,
         0, 0, 0, 1]
body_T_cam1: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [0.9998326094055786, -0.01317931478898709, 0.01269089559189768, 0.06038933631975229,
         0.01298734678025223, 0.999801762507382, 0.01509186902746622, -0.06753424960055816,
         -0.01288728027324361, -0.01492452172853483, 0.999805569427543, 0.03633758435321684,
         0, 0, 0, 1]
         
#estimation
estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
estimate_td: 0                      # online estimate time offset between camera and imu
td: 0.00                             # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)
estimation_mode: 0 #0:single; 1:solve all; 2: distributed; 3:server
double_counting_common_feature: 0
not_estimate_first_extrinsic: 1

#optimization parameters
max_solver_time: 0.08 # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
consensus_max_steps: 1
timout_wait_sync: 100
rho_landmark: 1.0
rho_frame_T: 100
rho_frame_theta: 100
relaxation_alpha: 0.
consensus_sync_for_averaging: 0
consensus_sync_to_start: 0 #Is sync on start of the solving..
consensus_trigger_time_err_us: 100

#depth fusing
depth_far_thres: 3.0 # The max depth in frontend
depth_near_thres: 0.3 
fuse_dep: 0 #if fuse depth measurement
max_depth_to_fuse: 5.0
min_depth_to_fuse: 0.3

#Multi-drone
track_remote_netvlad_thres: 0.5

#Initialization
init_method: 0 #0 IMU, 1 PnP
depth_estimate_baseline: 0.05
enable_sfm_initialization: 0

#sliding window
max_sld_win_size: 11
landmark_estimate_tracks: 4 #when use depth or stereo, 3 is OK.
min_solve_frames: 6

#outlier rejection
thres_outlier : 10.0
perform_outlier_rejection_num: 30
tri_max_err: 10

#Marginalization
enable_marginalization: 1
margin_sparse_solver: 0
always_fixed_first_pose: 0
remove_base_when_margin_remote: 2
#  When set to 2, will use the all relevant measurements of the removing frames to compute the prior,
# and the baseFrame (where!=removeID) will not be removed. This may lead to double counting of this baseFrame measurement: but it's stable.
#  When set to 1, will remove the baseframe's measurements of those measurements which is not base on current frame.
#  set to 0 those measurements (which on a landmark's baseFrame is not been removed) will be ignore.

#feature tracker parameters
max_cnt: 200            # max feature number in feature tracking
max_superpoint_cnt: 250 # max feature extraction by superpoint
max_solve_cnt: 250
show_track_id: 0
check_essential: 0
enable_lk_optical_flow: 1 #enable lk opticalflow featuretrack to enhance ego-motion estimation.
remote_min_match_num: 40
ransacReprojThreshold: 10.0
parallex_thres: 0.02
knn_match_ratio: 0.7 #This apply to superpoint feature track & loop clouse detection.
feature_min_dist: 20
sp_track_use_lk: 1

#CNN
cnn_use_onnx: 1
enable_pca_superpoint: 0
enable_pca_netvlad: 0
cnn_enable_tensorrt: 0
cnn_enable_tensorrt_int8: 0
netvlad_int8_calib_table_name: "mobilenetvlad_calibration.flatbuffers"
superpoint_int8_calib_table_name: "superpoint_calibration.flatbuffers"

# #Measurement parameters       The more accurate parameters you provide, the better performance
acc_n: 0.1          # accelerometer measurement noise standard deviation. 
gyr_n: 0.05         # gyroscope measurement noise standard deviation.
acc_w: 0.002         # accelerometer bias random work noise standard deviation.
gyr_w: 0.0004       # gyroscope bias random work noise standard deviation.
g_norm: 9.81         # gravity magnitude

#Loop Closure Detection
loop_detection_netvlad_thres: 0.8
enable_homography_test: 0
accept_loop_max_yaw: 10
accept_loop_max_pos: 1.0
loop_inlier_feature_num: 20
gravity_check_thres: 0.06
pgo_solver_time: 1.0
solver_timer_freq: 1.0
enable_pcm: 1
pcm_thres: 2.8


#PGO
pgo_solver_time: 1.0
solver_timer_freq: 0.2
pgo_mode: 0
pgo_rho_frame_T: 0.01
pgo_rho_frame_theta: 2.0 
pgo_eta_k: 1.0
write_g2o: 1
g2o_output_path: "output.g2o"
write_pgo_to_file: 1
debug_save_g2o_only: 0


#outputs
output_path: "/home/xuhao/data/d2slam/mit_campus_hybrid/outputs/"
debug_print_sldwin: 0
debug_print_states: 0
enable_perf_output: 0
debug_write_margin_matrix: 0
