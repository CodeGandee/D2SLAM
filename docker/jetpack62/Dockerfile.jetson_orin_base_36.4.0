#Ubuntu 20.04 for ROS Noetic compatibility in Docker on JetPack 6.2 host
# Using Ubuntu 20.04 base + L4T CUDA runtime for proper ROS Noetic support
# The L4T drivers will be mounted from the JetPack 6.2 host system
FROM nvcr.io/nvidia/l4t-cuda:12.6.11-runtime
ARG CERES_VERSION=2.1.0
# Remove ONNX_VERSION as we're using prebuilt wheels
ENV SWARM_WS=/root/swarm_ws
ARG CMAKE_VERSION=3.24.1
ARG OPENCV_VERSION=4.10.0
ARG ROS_VERSION=noetic
ARG FAISS_VERSION=1.7.4
#Modified if use PC
ARG USE_PROC=8
ENV SWARM_WS=/root/swarm_ws
ENV DEBIAN_FRONTEND=noninteractive
# Orin and Orin NX support compute capability 8.7
ARG CUDA_ARCH_BIN="8.7"
ARG ENABLE_NEON="ON"

#Some basic dependencies and L4T components for Ubuntu 20.04
RUN   apt-get -y update && \
      TZ=Asia/Beijing apt-get -y install tzdata && \
      apt-get install -y wget curl lsb-release git \
      libatlas-base-dev \
      libeigen3-dev \
      libgoogle-glog-dev \
      libsuitesparse-dev \
      libglib2.0-dev \
      libyaml-cpp-dev \
      net-tools \
      htop \
      xterm \
      gdb \
      zip \
      unzip \
      libdw-dev \
      vim \
      xterm \
      software-properties-common \
      ca-certificates \
      gnupg

# Install TensorRT for JetPack 6.2 on Ubuntu 20.04
# Try multiple approaches for TensorRT installation
RUN   set -e && \
      # Method 1: Try with CUDA keyring
      (wget --timeout=30 --tries=3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/sbsa/cuda-keyring_1.0-1_all.deb && \
       dpkg -i cuda-keyring_1.0-1_all.deb && \
       apt-get update && \
       apt-get install -y --no-install-recommends \
         libnvinfer10 libnvinfer-plugin10 libnvparsers10 libnvonnxparsers10 \
         libnvinfer-dev libnvinfer-plugin-dev libnvparsers-dev libnvonnxparsers-dev \
         python3-libnvinfer python3-libnvinfer-dev && \
       rm -f cuda-keyring_1.0-1_all.deb && \
       echo "TensorRT installed successfully via CUDA keyring") || \
      # Method 2: Try alternative keyring approach
      (wget --timeout=30 --tries=3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/sbsa/cuda-ubuntu2004.pin && \
       mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600 && \
       apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/sbsa/3bf863cc.pub && \
       add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/sbsa/ /" && \
       apt-get update && \
       apt-get install -y --no-install-recommends \
         libnvinfer10 libnvinfer-plugin10 libnvparsers10 libnvonnxparsers10 \
         libnvinfer-dev libnvinfer-plugin-dev libnvparsers-dev libnvonnxparsers-dev \
         python3-libnvinfer python3-libnvinfer-dev && \
       echo "TensorRT installed successfully via alternative method") || \
      # Method 3: Skip TensorRT for now (will use runtime mounting)
      (echo "Warning: TensorRT packages not available, will rely on host system TensorRT")

#ROS
#ROS Installation
RUN sh -c 'echo "deb http://packages.ros.org/ros/ubuntu focal main" > /etc/apt/sources.list.d/ros-latest.list' && \
      curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | apt-key add - && \
      apt-get update && \
      apt-get install -y  --no-install-recommends \
      ros-${ROS_VERSION}-ros-base \
      ros-${ROS_VERSION}-nav-msgs \
      ros-${ROS_VERSION}-sensor-msgs \
      ros-${ROS_VERSION}-cv-bridge \
      ros-${ROS_VERSION}-rviz \
      ros-${ROS_VERSION}-image-transport-plugins \
      ros-${ROS_VERSION}-pcl-ros \
      build-essential \
      ros-${ROS_VERSION}-catkin \
      python3-catkin-tools python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential && \
      rosdep init && rosdep update

#Replace CMAKE
RUN   rm /usr/bin/cmake && \
      wget https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/cmake-${CMAKE_VERSION}-Linux-aarch64.sh \
      -q -O /tmp/cmake-install.sh \
      && chmod u+x /tmp/cmake-install.sh \
      && /tmp/cmake-install.sh --skip-license --prefix=/usr/ \
      && rm /tmp/cmake-install.sh \
      && cmake --version

#Install OpenCV4 with CUDA
RUN   apt update && \
      apt install libgtk2.0-dev -y && \
      wget https://github.com/opencv/opencv/archive/${OPENCV_VERSION}.zip -O opencv.zip && \
      unzip opencv.zip && \
      rm opencv.zip && \
      git clone https://github.com/opencv/opencv_contrib.git -b ${OPENCV_VERSION} && \
      cd opencv-${OPENCV_VERSION} && \
      mkdir build && cd build && \
      cmake .. \
            -D CMAKE_BUILD_TYPE=RELEASE \
            -D CMAKE_INSTALL_PREFIX=/usr/local \
            -D WITH_CUDA=ON \
            -D WITH_CUDNN=ON \
            -D WITH_CUBLAS=ON \
            -D CUDA_ARCH_BIN=${CUDA_ARCH_BIN} \
            -D CUDA_ARCH_PTX= \
            -D CUDA_FAST_MATH=ON \
            -D WITH_TBB=ON \
            -D BUILD_opencv_python2=OFF \
            -D BUILD_opencv_python3=ON \
            -D OPENCV_DNN_CUDA=ON \
            -D OPENCV_ENABLE_NONFREE=ON \
            -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \
            -D BUILD_EXAMPLES=OFF \
            -D BUILD_opencv_java=OFF \
            -D BUILD_opencv_python=OFF \
            -D BUILD_TESTS=OFF \
            -D BUILD_PERF_TESTS=OFF \
            -D BUILD_opencv_apps=OFF \
            -D ENABLE_NEON=${ENABLE_NEON} \
            -D EIGEN_INCLUDE_PATH=/usr/include/eigen3 \
	      -D WITH_EIGEN=ON \
            -D WITH_IPP=OFF \
      	-D WITH_OPENCL=OFF \
            -D BUILD_LIST=calib3d,features2d,highgui,dnn,imgproc,imgcodecs,\
cudev,cudaoptflow,cudaimgproc,cudalegacy,cudaarithm,cudacodec,cudastereo,\
cudafeatures2d,xfeatures2d,tracking,stereo,\
aruco,videoio,ccalib && \
      make -j$(nproc) && \
      make install

RUN   git clone https://github.com/HKUST-Swarm/ceres-solver -b D2SLAM && \
      cd ceres-solver && \
      mkdir build && cd build && \
      cmake  -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF -DBUILD_BENCHMARKS=OFF -DCUDA=OFF .. && \
      make -j$(nproc) install && \
      rm -rf ../../ceres-solver && \
      apt-get clean all

#Install LCM
RUN   git clone https://github.com/lcm-proj/lcm && \
      cd lcm && \
      git checkout tags/v1.4.0 && \
      mkdir build && cd build && \
      cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF -DBUILD_BENCHMARKS=OFF .. && \
      make -j$(nproc) install

#Install Faiss
RUN   git clone -b v${FAISS_VERSION} --single-branch  https://github.com/facebookresearch/faiss.git && \
      cd faiss && \
      cmake -B build -DCMAKE_BUILD_TYPE=Release -DFAISS_ENABLE_PYTHON=OFF  -DFAISS_OPT_LEVEL=NEON -DBUILD_TESTING=OFF -DFAISS_ENABLE_GPU=OFF . && \
      make -C build -j$(nproc) faiss && \
      make -C build install && \
      rm -rf ../faiss

#Install OpenGV
RUN   git clone https://github.com/HKUST-Swarm/opengv && \
      mkdir opengv/build && cd opengv/build && cmake .. && make -j$(nproc) && \
      make install

#Install Backward
RUN   wget https://raw.githubusercontent.com/bombela/backward-cpp/master/backward.hpp -O /usr/local/include/backward.hpp

#Install ONNXRuntime with CUDA and TensorRT - Build from source for Ubuntu 20.04
# Need to build from source since prebuilt wheels may not be compatible with Ubuntu 20.04
RUN   apt install python3-pip libopenblas-dev vim python3-dev -y && \
      pip3 install numpy cmake

# Build ONNX Runtime from source with CUDA support (TensorRT optional)
RUN   git clone -b v1.18.0 --single-branch --recursive https://github.com/Microsoft/onnxruntime && \
      cd onnxruntime && \
      # Try with TensorRT first, fallback to CUDA only
      (./build.sh --config Release --build_shared_lib --parallel \
       --use_cuda --cudnn_home /usr/lib/aarch64-linux-gnu --cuda_home /usr/local/cuda --skip_test \
       --use_tensorrt --tensorrt_home /usr && \
       echo "ONNX Runtime built with TensorRT support") || \
      (echo "TensorRT not available, building with CUDA only" && \
       ./build.sh --config Release --build_shared_lib --parallel \
       --use_cuda --cudnn_home /usr/lib/aarch64-linux-gnu --cuda_home /usr/local/cuda --skip_test) && \
      cd build/Linux/Release && \
      make install && \
      rm -rf ../../../onnxruntime

# Install PyTorch for JetPack 6.2 on Ubuntu 20.04 - Multiple fallback options
RUN   set -e && \
      # Method 1: Try jetson-ai-lab packages
      (pip3 install --timeout=300 torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 \
       --index-url https://elinux.org/jetson-packages/jp6/cu126 && \
       echo "PyTorch installed from jetson-ai-lab") || \
      # Method 2: Try CUDA 12.1 wheels
      (echo "Trying PyTorch with CUDA 12.1 wheels" && \
       pip3 install --timeout=300 torch torchvision torchaudio \
       --index-url https://download.pytorch.org/whl/cu121) || \
      # Method 3: Try CPU-only version as last resort
      (echo "Installing CPU-only PyTorch as fallback" && \
       pip3 install --timeout=300 torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu)

# Install for TaichiSLAM
RUN   pip install transformations numpy lcm matplotlib scipy && apt install ros-${ROS_VERSION}-ros-numpy -y

#Install spdlog
RUN   wget https://github.com/gabime/spdlog/archive/refs/tags/v1.12.0.tar.gz && \
      tar -zxvf v1.12.0.tar.gz && \
      cd spdlog-1.12.0 && \
      mkdir build && cd build && \
      cmake .. && make -j$(nproc) && \
      make install
